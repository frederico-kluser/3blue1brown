# Manim Video Generator API

Backend FastAPI que converte descri√ß√µes em linguagem natural em cenas Manim renderizadas com suporte a OpenAI GPT-5.1 Codex Max.

## Vis√£o geral
- **Stack**: Python 3.11, FastAPI, Manim CE 0.19.0, Async OpenAI API.
- **Fluxo**: descri√ß√£o ‚Üí LLM gera c√≥digo ‚Üí valida√ß√£o AST ‚Üí renderiza√ß√£o via CLI ‚Üí resposta JSON/base64.
- **Entrega**: Endpoints para health-check, gera√ß√£o de c√≥digo e gera√ß√£o de v√≠deo (base64 ou arquivo).

## Setup r√°pido via terminal
1. Instale FFmpeg, Cairo, Pango, pkg-config, LaTeX e Cloudflared seguindo `TUTORIAL.md` (h√° receitas para macOS/Homebrew e Ubuntu/Debian). Confirme com `ffmpeg --version` e `latex --version`.
2. Crie e ative o ambiente virtual:
   ```bash
   cd manim-api
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   cp .env.example .env  # edite com sua OPENAI_API_KEY
   ```
3. Suba o servidor diretamente com o Uvicorn:
   ```bash
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```
4. Para sess√µes futuras, apenas ative o `venv` e execute novamente o comando do Uvicorn. Atualize depend√™ncias com `pip install -r requirements.txt --upgrade` quando necess√°rio.

## Cloudflare Tunnel sem login
1. Instale o bin√°rio (`brew install cloudflared` no macOS ou siga a doc oficial no Linux).
2. Gere um link p√∫blico ef√™mero direto no terminal:
   ```bash
   cloudflared tunnel --url http://localhost:8000 --no-autoupdate
   ```
   - A sa√≠da exibir√° uma URL `https://<algo>.trycloudflare.com` que pode ser usada imediatamente a partir do front-end.
   - Ajuste a porta trocando o valor ap√≥s `--url`.
3. Para um t√∫nel persistente com dom√≠nio pr√≥prio, siga os passos padr√£o da Cloudflare: `cloudflared tunnel login`, `cloudflared tunnel create <nome>`, configure `~/.cloudflared/config.yml` apontando para `http://localhost:8000` e finalize com `cloudflared tunnel run <nome>` (ou instale o servi√ßo via `cloudflared service install`).

## Integra√ß√£o com OpenAI Responses API
- **Modelo √∫nico**: `gpt-5.1-codex-max`, acessado exclusivamente pelo endpoint `/v1/responses` (n√£o funciona em Chat Completions).
- **Esfor√ßo de racioc√≠nio**: sempre `reasoning={"effort": "xhigh"}` para maximizar consist√™ncia em cenas complexas.
- **Formato de chamada**:
  ```python
  from openai import AsyncOpenAI

  client = AsyncOpenAI()
  response = await client.responses.create(
      model="gpt-5.1-codex-max",
      input=[
          {"role": "system", "content": "instrua a cria√ß√£o de cenas Manim CE"},
          {"role": "user", "content": prompt_otimizado}
      ],
      reasoning={"effort": "xhigh"}
  )
  code = response.output_text
  ```
- Toda a API usa esse formato tanto para otimizar o prompt quanto para gerar o c√≥digo final; o servi√ßo extrai texto via `response.output_text` antes de validar com AST.

## Pipeline inteligente com gpt-5.1-codex-max
1. **Otimiza√ß√£o de prompt** ‚Äì o servi√ßo chama `gpt-5.1-codex-max` (Responses API) para interpretar a descri√ß√£o original, anexar o invent√°rio de recursos (FastAPI, executor Manim, valida√ß√µes AST, Cloudflare Tunnel) e gerar uma vers√£o enriquecida do pedido.
2. **Gera√ß√£o de c√≥digo** ‚Äì o prompt otimizado, acompanhado das capacidades dispon√≠veis, alimenta um segundo request ao mesmo modelo (tamb√©m via Responses API) para emitir o c√≥digo Manim final seguindo o template CE.
3. **Valida√ß√£o + render** ‚Äì o c√≥digo passa por AST e listas de bloqueio antes de chegar ao executador Manim/FFmpeg, garantindo seguran√ßa e cenas < 30s.

## Endpoints principais
- `GET /` ‚Äì Health check com vers√£o do Manim e modelo OpenAI.
- `POST /generate-code` ‚Äì Retorna apenas o c√≥digo Manim gerado e validado.
- `POST /generate-video` ‚Äì Retorna v√≠deo em base64 (JSON `VideoResponse`).
- `POST /generate-video-file` ‚Äì Faz download direto do MP4.

Consulte `TUTORIAL.md` para pipeline completo, testes end-to-end e configura√ß√£o do Cloudflare Tunnel.

## Vis√£o detalhada do projeto

### O que o projeto faz
- API FastAPI que aceita descri√ß√µes em linguagem natural, usa o GPT-5.1 Codex Max para gerar c√≥digo Manim CE 0.19.x, valida o c√≥digo e renderiza a cena via CLI, retornando v√≠deo em base64 ou arquivo MP4.
- Stack principal: Python 3.11, FastAPI, Manim CE, OpenAI SDK async, FFmpeg/LaTeX/Cairo como depend√™ncias nativas.

### Como consumir
1. Suba o servidor local: `cd manim-api && source venv/bin/activate && uvicorn main:app --host 0.0.0.0 --port 8000`.
2. Use os endpoints documentados (`/generate-code`, `/generate-video`, `/generate-video-file`) enviando JSON `{ "description": "..." }`; envie `width`/`height` apenas se quiser outra resolu√ß√£o (padr√£o 1920x1080 16:9).
3. A cole√ß√£o Postman `postman_collection.json` pode ser importada e parametrizada com `{{base_url}}` (`http://localhost:8000` ou o link Cloudflare).

### Localhost e link p√∫blico simult√¢neos
- Execute o servidor normalmente em `localhost:8000`.
- Em outro terminal, rode `cloudflared tunnel --url http://localhost:8000 --no-autoupdate` para criar um t√∫nel ef√™mero `.trycloudflare.com` sem login.
- Ambos funcionam em paralelo: clientes locais usam `http://localhost:8000` e usu√°rios remotos usam o dom√≠nio fornecido pelo Cloudflare.

### Configura√ß√µes principais
- `.env` define `OPENAI_API_KEY`, `OPENAI_MODEL`, `RENDER_TIMEOUT`, `HOST`, `PORT`, `DEBUG`. A resolu√ß√£o √© informada por request (campos opcionais `width`/`height`, padr√£o 1920x1080 em 16:9).
- Depend√™ncias de sistema: FFmpeg, libcairo, pango, pkg-config e LaTeX m√≠nimo.

### Cole√ß√£o Postman
- Localizada em `manim-api/postman_collection.json` com requests para health, c√≥digo e v√≠deo.
- Atualize a vari√°vel `base_url` conforme o endpoint utilizado (localhost ou t√∫nel).

## Tutorial completo

# Backend API para Gera√ß√£o de V√≠deos Manim via LLM

O stack recomendado para construir este MVP √© **Python 3.11 + FastAPI + OpenAI GPT-5.1 Codex Max + Manim CE 0.19.0**, com exposi√ß√£o via **Cloudflare Tunnel gratuito**. Com dedica√ß√£o focada, um desenvolvedor pode ter o sistema funcional em **4-8 horas** seguindo este guia.

A arquitetura proposta recebe descri√ß√µes em linguagem natural, transforma em c√≥digo Manim via LLM, executa via subprocess isolado, e retorna o v√≠deo renderizado como base64 ou arquivo direto. O Cloudflare Tunnel elimina a necessidade de IP fixo ou portas abertas, fornecendo HTTPS autom√°tico gratuitamente.

---

## 1. Sum√°rio executivo

### Stack tecnol√≥gico recomendado

| Componente | Tecnologia | Vers√£o | Justificativa |
|------------|-----------|--------|---------------|
| **Runtime** | Python | 3.11+ | Melhor compatibilidade Manim CE |
| **API Framework** | FastAPI | 0.109+ | Async nativo, tipagem forte, docs autom√°ticos |
| **LLM** | OpenAI GPT-5.1 Codex Max | latest | Modelo de c√≥digo especializado recomendado para todas as fases |
| **Renderiza√ß√£o** | Manim CE | 0.19.0 | Vers√£o de Janeiro 2025, ativamente mantido |
| **V√≠deo** | FFmpeg | latest | Depend√™ncia obrigat√≥ria do Manim |
| **Exposi√ß√£o** | Cloudflare Tunnel | gratuito | HTTPS autom√°tico, sem portas abertas |

### Custo estimado por request
- **GPT-5.1 Codex Max**: consulte a tabela oficial do link https://platform.openai.com/docs/models/gpt-5.1-codex-max. Para refer√™ncia, com ~500 tokens de entrada e ~800 de sa√≠da projetamos ~US$0.0006 por chamada.
- Para 1000 v√≠deos/m√™s: or√ßamento aproximado de **US$0.60** (ajuste conforme m√©tricas reais).

### Tempo estimado at√© MVP funcional

| Fase | Tempo | Descri√ß√£o |
|------|-------|-----------|
| Setup ambiente | 30-60 min | Depend√™ncias, Python, FFmpeg, LaTeX |
| C√≥digo API | 1-2 horas | FastAPI + OpenAI integration |
| Teste/Debug | 1-2 horas | Ajustes de prompts e pipeline |
| Cloudflare Tunnel | 30 min | Configura√ß√£o e exposi√ß√£o |
| **Total** | **4-8 horas** | Sistema funcional end-to-end |

---

## 2. Setup de ambiente

### 2.1 Pr√©-requisitos de sistema

**Sistema Operacional:** Ubuntu 22.04/24.04 LTS (recomendado) ou Debian 12

**Vers√µes testadas:**
- Python 3.11 ou 3.12
- FFmpeg 5.x ou 6.x
- Manim CE 0.19.0 (lan√ßado 20/01/2025)

### 2.2 Instala√ß√£o de depend√™ncias do sistema

```bash
# Atualizar sistema
sudo apt update && sudo apt upgrade -y

# Depend√™ncias essenciais para Manim
sudo apt install -y \
    build-essential \
    python3-dev \
    python3-pip \
    python3-venv \
    libcairo2-dev \
    libpango1.0-dev \
    pkg-config \
    ffmpeg

# LaTeX (necess√°rio para MathTex e f√≥rmulas matem√°ticas)
# Vers√£o m√≠nima (~300MB):
sudo apt install -y texlive-latex-base texlive-fonts-recommended

# Vers√£o completa (~2GB, recomendada para MVP robusto):
# sudo apt install -y texlive texlive-latex-extra texlive-fonts-extra texlive-science

# Verificar instala√ß√µes
ffmpeg -version
python3 --version
```

### 2.3 Estrutura de diret√≥rios do projeto

```
manim-api/
‚îú‚îÄ‚îÄ main.py              # Servidor FastAPI principal
‚îú‚îÄ‚îÄ config.py            # Configura√ß√µes e settings
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ openai_service.py    # Integra√ß√£o com OpenAI
‚îÇ   ‚îî‚îÄ‚îÄ manim_executor.py    # Execu√ß√£o segura do Manim
‚îú‚îÄ‚îÄ schemas.py           # Modelos Pydantic
‚îú‚îÄ‚îÄ prompts.py           # System prompts e exemplos
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias Python
‚îú‚îÄ‚îÄ .env                 # Vari√°veis de ambiente (N√ÉO commitar)
‚îú‚îÄ‚îÄ .env.example         # Template do .env
‚îî‚îÄ‚îÄ README.md
```

### 2.4 Cria√ß√£o do ambiente virtual e depend√™ncias

```bash
# Criar diret√≥rio do projeto
mkdir manim-api && cd manim-api

# Criar ambiente virtual
python3 -m venv venv
source venv/bin/activate

# Instalar depend√™ncias
pip install --upgrade pip
pip install -r requirements.txt

# Verificar instala√ß√£o do Manim
manim --version
# Esperado: Manim Community v0.19.0
```

### 2.5 Arquivo requirements.txt completo

```txt
# requirements.txt

# Web Framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0

# OpenAI
openai>=1.12.0

# Validation & Settings
pydantic>=2.5.0
pydantic-settings>=2.1.0

# Environment
python-dotenv>=1.0.0

# Manim (Community Edition)
manim>=0.19.0

# Utilities
aiofiles>=23.2.1
python-multipart>=0.0.6

# Dev/Testing (opcional)
pytest>=7.4.0
httpx>=0.26.0
```

### 2.6 Arquivo .env template

```bash
# .env.example (copiar para .env e preencher)

# OpenAI Configuration
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-5.1-codex-max

# App Configuration
APP_NAME="Manim Video Generator API"
DEBUG=false

# Manim Configuration
MANIM_QUALITY=l  # l=low(480p), m=medium(720p), h=high(1080p)
RENDER_TIMEOUT=120  # segundos

# Server
HOST=0.0.0.0
PORT=8000
```

---

## 3. C√≥digo do servidor API

### 3.1 Arquivo config.py

```python
# config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from functools import lru_cache

class Settings(BaseSettings):
    # OpenAI
    openai_api_key: str
    openai_model: str = "gpt-5.1-codex-max"
    
    # App
    app_name: str = "Manim Video Generator API"
    debug: bool = False
    
    # Manim
    render_timeout: int = 120
    
    # Server
    host: str = "0.0.0.0"
    port: int = 8000
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore",
    )

@lru_cache
def get_settings() -> Settings:
    return Settings()
```

### 3.2 Arquivo schemas.py

```python
# schemas.py
from pydantic import BaseModel, Field
from typing import Optional

class VideoRequest(BaseModel):
    description: str = Field(
        ..., 
        min_length=10, 
        max_length=2000,
        description="Descri√ß√£o em linguagem natural do v√≠deo desejado"
    )
    width: int | None = Field(
        default=None,
        ge=320,
        le=3840,
        description="(Opcional) Largura do v√≠deo em pixels"
    )
    height: int | None = Field(
        default=None,
        ge=320,
        le=3840,
        description="(Opcional) Altura do v√≠deo em pixels"
    )

class CodeResponse(BaseModel):
    code: str
    scene_name: str
    is_valid: bool
    validation_message: str

class VideoResponse(BaseModel):
    success: bool
    video_base64: Optional[str] = None
    content_type: str = "video/mp4"
    scene_name: Optional[str] = None
    error: Optional[str] = None
    render_logs: Optional[str] = None

class HealthResponse(BaseModel):
    status: str
    manim_version: str
    openai_model: str
```

### 3.3 Arquivo prompts.py

```python
# prompts.py

MANIM_SYSTEM_PROMPT = """You are an expert Manim Community Edition developer. Generate valid, executable Manim code based on user descriptions.

## CRITICAL RULES:
1. ALWAYS use `from manim import *` (Community Edition syntax)
2. Create a SINGLE Scene class with a descriptive PascalCase name
3. Implement the `construct(self)` method with all animations
4. Use `self.play()` for EVERY animation
5. ALWAYS end with `self.wait()` or `self.wait(1)` for proper video ending
6. Keep total animation duration under 30 seconds
7. Use smooth, professional animation timings (run_time=1 to 2 seconds)

## CODE TEMPLATE:
```python
from manim import *

class SceneName(Scene):
    def construct(self):
        # Create objects
        # Animate with self.play()
        self.wait()
```

## AVAILABLE MOBJECTS:
- Shapes: Circle, Square, Rectangle, Triangle, Polygon, Line, Arrow, Dot, Arc
- Text: Text(\"text\"), MathTex(\"LaTeX\"), Tex(\"LaTeX text\")
- Groups: VGroup, Group
- Graphs: Axes, NumberPlane, FunctionGraph
- Colors: RED, BLUE, GREEN, YELLOW, WHITE, PURPLE, ORANGE, PINK, TEAL

## KEY ANIMATIONS:
- Create(mobject) - draws progressively
- Write(text) - writing animation for text
- FadeIn(mobject), FadeOut(mobject)
- Transform(source, target), ReplacementTransform(source, target)
- mobject.animate.method() - animate any property change
- Rotate(mobject, angle=PI), Scale(mobject, factor)
- GrowFromCenter(mobject)

## POSITIONING:
- .to_edge(UP/DOWN/LEFT/RIGHT)
- .shift(LEFT * 2), .shift(RIGHT * 3 + UP * 1)
- .move_to(ORIGIN), .next_to(other, RIGHT)
- Constants: UP, DOWN, LEFT, RIGHT, ORIGIN, UL, UR, DL, DR

## OUTPUT FORMAT:
Return ONLY the Python code wrapped in ```python ``` markers.
NO explanations before or after the code.
"""

FEW_SHOT_EXAMPLES = [
    {
        "user": "Create a blue circle that grows and then moves to the right",
        "assistant": """```python
from manim import *

class BlueCircleAnimation(Scene):
    def construct(self):
        circle = Circle(color=BLUE, fill_opacity=0.7)
        self.play(GrowFromCenter(circle), run_time=1)
        self.play(circle.animate.shift(RIGHT * 3), run_time=1.5)
        self.wait()
```"""
    },
    {
        "user": "Show the equation E=mc¬≤ appearing letter by letter",
        "assistant": """```python
from manim import *

class EinsteinEquation(Scene):
    def construct(self):
        equation = MathTex("E", "=", "m", "c^2")
        equation.scale(2)
        
        self.play(Write(equation[0]), run_time=0.5)
        self.play(Write(equation[1]), run_time=0.3)
        self.play(Write(equation[2]), run_time=0.5)
        self.play(Write(equation[3]), run_time=0.7)
        
        self.play(equation.animate.set_color(YELLOW), run_time=0.5)
        self.wait()
```"""
    },
    {
        "user": "Transform a red square into a green triangle",
        "assistant": """```python
from manim import *

class SquareToTriangle(Scene):
    def construct(self):
        square = Square(color=RED, fill_opacity=0.8)
        triangle = Triangle(color=GREEN, fill_opacity=0.8)
        
        self.play(Create(square), run_time=1)
        self.wait(0.5)
        self.play(Transform(square, triangle), run_time=1.5)
        self.wait()
```"""
    }
]


def build_messages(user_prompt: str) -> list:
    """Constr√≥i lista de mensagens com few-shot examples."""
    messages = [{"role": "system", "content": MANIM_SYSTEM_PROMPT}]
    
    for example in FEW_SHOT_EXAMPLES:
        messages.append({"role": "user", "content": example["user"]})
        messages.append({"role": "assistant", "content": example["assistant"]})
    
    messages.append({"role": "user", "content": user_prompt})
    
    return messages
```

### 3.4 Arquivo services/openai_service.py

```python
# services/openai_service.py
import re
import ast
from openai import AsyncOpenAI
from config import get_settings
from prompts import build_messages
from schemas import CodeResponse

settings = get_settings()
client = AsyncOpenAI(api_key=settings.openai_api_key)

# Valida√ß√£o de seguran√ßa
DANGEROUS_IMPORTS = {
    'os', 'sys', 'subprocess', 'shutil', 'socket', 'urllib',
    'requests', 'pickle', 'ctypes', 'multiprocessing', 'pty'
}

DANGEROUS_FUNCTIONS = {'eval', 'exec', 'open', '__import__', 'compile'}


def extract_code(response: str) -> str:
    """Extrai c√≥digo Python de resposta markdown."""
    pattern = r"```python\s*(.*?)\s*```"
    matches = re.findall(pattern, response, re.DOTALL)
    if matches:
        return matches[0].strip()
    
    # Fallback: c√≥digo sem marcadores
    if "from manim import" in response:
        return response.strip()
    
    raise ValueError("Could not extract valid Manim code from response")


def get_scene_name(code: str) -> str:
    """Extrai nome da classe Scene do c√≥digo."""
    pattern = r"class\s+(\w+)\s*\(\s*(?:Scene|ThreeDScene|MovingCameraScene)\s*\)"
    match = re.search(pattern, code)
    if match:
        return match.group(1)
    raise ValueError("Could not find Scene class in code")


def validate_code(code: str) -> tuple[bool, str]:
    """Valida c√≥digo Manim antes de executar."""
    # 1. Verificar sintaxe Python
    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        return False, f"Syntax error: {e}"
    
    # 2. Verificar import obrigat√≥rio
    if "from manim import" not in code:
        return False, "Missing 'from manim import' statement"
    
    # 3. Verificar classe Scene
    if "(Scene)" not in code and "(ThreeDScene)" not in code:
        return False, "Missing Scene class definition"
    
    # 4. Verificar m√©todo construct
    if "def construct(self)" not in code:
        return False, "Missing construct method"
    
    # 5. Verificar imports/fun√ß√µes perigosas
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                module = alias.name.split('.')[0]
                if module in DANGEROUS_IMPORTS:
                    return False, f"Forbidden import: {alias.name}"
        
        elif isinstance(node, ast.ImportFrom):
            module = (node.module or '').split('.')[0]
            if module in DANGEROUS_IMPORTS:
                return False, f"Forbidden import: from {node.module}"
        
        elif isinstance(node, ast.Call):
            if isinstance(node.func, ast.Name):
                if node.func.id in DANGEROUS_FUNCTIONS:
                    return False, f"Forbidden function: {node.func.id}()"
    
    return True, "Code validated successfully"


async def generate_manim_code(description: str) -> CodeResponse:
    """Gera c√≥digo Manim a partir de descri√ß√£o em linguagem natural."""
    try:
        messages = build_messages(description)
        
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=messages,
            temperature=0.2,  # Baixa para c√≥digo determin√≠stico
            max_tokens=2000
        )
        
        raw_response = response.choices[0].message.content
        code = extract_code(raw_response)
        scene_name = get_scene_name(code)
        is_valid, message = validate_code(code)
        
        return CodeResponse(
            code=code,
            scene_name=scene_name,
            is_valid=is_valid,
            validation_message=message
        )
        
    except Exception as e:
        return CodeResponse(
            code="",
            scene_name="",
            is_valid=False,
            validation_message=str(e)
        )
```

### 3.5 Arquivo services/manim_executor.py

```python
# services/manim_executor.py
import base64
import os
import subprocess
import tempfile
from dataclasses import dataclass
from pathlib import Path
from typing import Optional
from config import get_settings

settings = get_settings()


@dataclass
class RenderResult:
    success: bool
    video_path: Optional[str] = None
    video_base64: Optional[str] = None
    stdout: str = ""
    stderr: str = ""
    error: Optional[str] = None


def _resolve_texlive_bin() -> Optional[Path]:
    texlive_root = Path.home() / "texlive"
    if not texlive_root.exists():
        return None
    candidates = sorted(texlive_root.glob("*/bin/*"), reverse=True)
    for candidate in candidates:
        if candidate.is_dir():
            return candidate
    return None


def find_video(media_dir: Path, scene_name: str) -> Optional[Path]:
    """Localiza o MP4 independente da pasta/qualidade utilizada."""
    expected_root = media_dir / "videos"
    candidates = sorted(
        expected_root.rglob("*.mp4") if expected_root.exists() else media_dir.rglob("*.mp4"),
        key=lambda path: path.stat().st_mtime,
        reverse=True,
    )
    for mp4 in candidates:
        if scene_name in mp4.stem:
            return mp4
    return candidates[0] if candidates else None


def execute_manim(
    code: str,
    scene_name: str,
    width: int = 1920,
    height: int = 1080,
    timeout: int = 120,
) -> RenderResult:
    with tempfile.TemporaryDirectory(prefix="manim_") as tmpdir:
        work_dir = Path(tmpdir)
        script_path = work_dir / "scene.py"
        media_dir = work_dir / "media"
        script_path.write_text(code)

        cmd = [
            "manim",
            "render",
            "-r",
            f"{width},{height}",
            "--fps",
            "60",
            "--media_dir",
            str(media_dir),
            "--disable_caching",
            str(script_path),
            scene_name,
        ]

        env = os.environ.copy()
        texlive_bin = _resolve_texlive_bin()
        if texlive_bin and texlive_bin.exists():
            env["PATH"] = f"{texlive_bin}:{env.get('PATH', '')}"

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout,
                cwd=str(work_dir),
                env=env,
            )
        except subprocess.TimeoutExpired as exc:
            return RenderResult(
                success=False,
                error=f"Render timeout after {timeout} seconds",
                stdout=exc.stdout or "",
                stderr=exc.stderr or "",
            )
        except Exception as exc:
            return RenderResult(success=False, error=f"Subprocess error: {exc}")

        if result.returncode != 0:
            return RenderResult(
                success=False,
                error="Manim render failed",
                stdout=result.stdout,
                stderr=result.stderr,
            )

        video_path = find_video(media_dir, scene_name)
        if not video_path:
            return RenderResult(
                success=False,
                error="Video file not found after render",
                stdout=result.stdout,
                stderr=result.stderr,
            )

        video_b64 = base64.b64encode(video_path.read_bytes()).decode("utf-8")
        return RenderResult(
            success=True,
            video_path=str(video_path),
            video_base64=video_b64,
            stdout=result.stdout,
            stderr=result.stderr,
        )
```

### 3.6 Arquivo main.py - Servidor completo

```python
# main.py
import subprocess
from fastapi import FastAPI, HTTPException
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware

from config import get_settings
from schemas import (
    VideoRequest, VideoResponse, CodeResponse, HealthResponse
)
from services.openai_service import generate_manim_code
from services.manim_executor import execute_manim

settings = get_settings()

app = FastAPI(
    title=settings.app_name,
    description="API para gerar v√≠deos Manim via descri√ß√µes em linguagem natural",
    version="1.0.0"
)

# CORS para acesso externo
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Ajustar em produ√ß√£o
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/", response_model=HealthResponse)
async def health():
    """Health check com informa√ß√µes do sistema."""
    try:
        result = subprocess.run(
            ["manim", "--version"],
            capture_output=True,
            text=True,
            timeout=5
        )
        manim_version = result.stdout.strip() if result.returncode == 0 else "unknown"
    except Exception:
        manim_version = "error"
    
    return HealthResponse(
        status="healthy",
        manim_version=manim_version,
        openai_model=settings.openai_model
    )


@app.post("/generate-code", response_model=CodeResponse)
async def generate_code(request: VideoRequest):
    """
    Gera c√≥digo Manim a partir de descri√ß√£o, sem renderizar.
    √ötil para debug e preview do c√≥digo.
    """
    return await generate_manim_code(
        description=request.description,
        width=request.width,
        height=request.height,
    )


@app.post("/generate-video", response_model=VideoResponse)
async def generate_video(request: VideoRequest):
    """
    Endpoint principal: gera c√≥digo Manim e renderiza v√≠deo.
    Retorna v√≠deo como base64.
    """
    # 1. Gerar c√≥digo via LLM
    code_result = await generate_manim_code(
        description=request.description,
        width=request.width,
        height=request.height,
    )

    if not code_result.is_valid:
        return VideoResponse(
            success=False,
            error=f"Code generation failed: {code_result.validation_message}"
        )
    
    # 2. Renderizar v√≠deo
    render_result = execute_manim(
        code=code_result.code,
        scene_name=code_result.scene_name,
        width=request.width,
        height=request.height,
        timeout=settings.render_timeout
    )

    if not render_result.success:
        return VideoResponse(
            success=False,
            error=render_result.error,
            render_logs=render_result.stderr
        )
    
    return VideoResponse(
        success=True,
        video_base64=render_result.video_base64,
        scene_name=code_result.scene_name
    )


@app.post("/generate-video-file")
async def generate_video_file(request: VideoRequest):
    """
    Gera v√≠deo e retorna arquivo MP4 diretamente (n√£o base64).
    Ideal para download direto.
    """
    # 1. Gerar c√≥digo via LLM
    code_result = await generate_manim_code(
        description=request.description,
        width=request.width,
        height=request.height,
    )

    if not code_result.is_valid:
        raise HTTPException(
            status_code=400,
            detail=f"Code generation failed: {code_result.validation_message}"
        )
    
    # 2. Renderizar v√≠deo
    render_result = execute_manim(
        code=code_result.code,
        scene_name=code_result.scene_name,
        width=request.width,
        height=request.height,
        timeout=settings.render_timeout
    )

    if not render_result.success:
        raise HTTPException(
            status_code=500,
            detail=f"Render failed: {render_result.error}\n{render_result.stderr}"
        )
    
    # Retornar arquivo diretamente
    import base64
    video_bytes = base64.b64decode(render_result.video_base64)
    
    return Response(
        content=video_bytes,
        media_type="video/mp4",
        headers={
            "Content-Disposition": f'attachment; filename="{code_result.scene_name}.mp4"'
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug
    )
```

---

## 4. Integra√ß√£o com OpenAI

### System prompt otimizado

O system prompt no arquivo `prompts.py` foi projetado com as seguintes caracter√≠sticas:

- **Regras expl√≠citas** de sintaxe Manim CE (n√£o ManimGL)
- **Template de c√≥digo** garantindo estrutura v√°lida
- **Lista de Mobjects e Animations** mais usados
- **Restri√ß√µes de dura√ß√£o** (m√°ximo 30 segundos)
- **Formato de output** for√ßando apenas c√≥digo em markdown

### Dupla etapa de prompts
1. `optimize_prompt()` ‚Üí chama `gpt-5.1-codex-max` para reescrever a descri√ß√£o, explicar suposi√ß√µes e detalhar como aproveitar os recursos dispon√≠veis.
2. `generate_manim_code()` ‚Üí usa o prompt enriquecido (com recursos e notas) para produzir o c√≥digo final do Manim CE.

### Par√¢metros de chamada recomendados

```python
response = await client.chat.completions.create(
    model="gpt-5.1-codex-max",     # Mais barato, suficiente para c√≥digo
    messages=messages,
    temperature=0.2,          # Baixa para c√≥digo determin√≠stico
    max_tokens=2000,          # Suficiente para scenes complexas
    top_p=0.95,              # Ligeira diversidade mantida
    frequency_penalty=0.0,    # N√£o penalizar repeti√ß√£o (normal em c√≥digo)
    presence_penalty=0.0
)
```

### Pol√≠tica de modelos

Todo o pipeline usa exclusivamente `gpt-5.1-codex-max`, tanto para otimiza√ß√£o de prompt quanto para gera√ß√£o do c√≥digo Manim. Isso elimina bifurca√ß√µes, garante consist√™ncia e simplifica a governan√ßa de custos: ajuste apenas os par√¢metros de tokens conforme seu workload.

---

## 5. Pipeline de renderiza√ß√£o

### Fluxo de execu√ß√£o completo

```
1. REQUEST           2. LLM              3. VALIDA√á√ÉO         4. RENDERIZA√á√ÉO
   ‚îÇ                    ‚îÇ                   ‚îÇ                    ‚îÇ
   ‚ñº                    ‚ñº                   ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Descri√ß√£o‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ OpenAI   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ ast.parse‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇsubprocess‚îÇ
‚îÇ em texto ‚îÇ      ‚îÇ GPT-5.1 Codex Max ‚îÇ        ‚îÇ validate ‚îÇ        ‚îÇ manim CLI‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ                   ‚îÇ                    ‚îÇ
                       ‚ñº                   ‚ñº                    ‚ñº
                  c√≥digo Manim        ‚úì v√°lido            /tmp/manim_xxx/
                  em Python           ‚úó erro              media/videos/
                                                               ‚îÇ
5. CAPTURA           6. CONVERS√ÉO        7. RESPONSE            ‚îÇ
   ‚îÇ                    ‚îÇ                   ‚îÇ                    ‚ñº
   ‚ñº                    ‚ñº                   ‚ñº               SceneName.mp4
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ find_video‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ base64   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  JSON    ‚îÇ
‚îÇ .mp4     ‚îÇ      ‚îÇ encode   ‚îÇ        ‚îÇ response ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Estrutura de arquivos tempor√°rios

```
/tmp/manim_abc123/
‚îú‚îÄ‚îÄ scene.py                    # C√≥digo gerado
‚îî‚îÄ‚îÄ media/
    ‚îî‚îÄ‚îÄ videos/
        ‚îî‚îÄ‚îÄ scene/
            ‚îî‚îÄ‚îÄ 480p15/
                ‚îú‚îÄ‚îÄ SceneName.mp4           # V√≠deo final
                ‚îî‚îÄ‚îÄ partial_movie_files/    # Frames intermedi√°rios
```

### Mapeamento de qualidade

| Flag | Pasta | Resolu√ß√£o | FPS | Tempo t√≠pico |
|------|-------|-----------|-----|--------------|
| `-ql` | 480p15 | 854√ó480 | 15 | 5-15s |
| `-qm` | 720p30 | 1280√ó720 | 30 | 15-30s |
| `-qh` | 1080p60 | 1920√ó1080 | 60 | 1-3min |
| `-qk` | 2160p60 | 3840√ó2160 | 60 | 5-10min |

---

## 6. Exposi√ß√£o via Cloudflare Tunnel

### Vis√£o geral

Cloudflare Tunnel √© **100% gratuito** e cria uma conex√£o segura do seu servidor local para a rede Cloudflare, sem necessidade de IP p√∫blico fixo ou portas abertas.

```
[Internet] ‚ÜêHTTPS‚Üí [Cloudflare Edge] ‚ÜêTunnel‚Üí [cloudflared] ‚ÜêHTTP‚Üí [localhost:8000]
```

### 6.1 Instala√ß√£o do cloudflared

```bash
# Ubuntu/Debian - via reposit√≥rio oficial
sudo mkdir -p --mode=0755 /usr/share/keyrings
curl -fsSL https://pkg.cloudflare.com/cloudflare-main.gpg | sudo tee /usr/share/keyrings/cloudflare-main.gpg > /dev/null

echo "deb [signed-by=/usr/share/keyrings/cloudflare-main.gpg] https://pkg.cloudflare.com/cloudflared any main" | sudo tee /etc/apt/sources.list.d/cloudflared.list

sudo apt-get update && sudo apt-get install -y cloudflared

# Verificar instala√ß√£o
cloudflared --version
```

### 6.2 Autentica√ß√£o e cria√ß√£o do tunnel

```bash
# 1. Autenticar (abre navegador ou exibe URL)
cloudflared tunnel login

# 2. Criar tunnel com nome identific√°vel
cloudflared tunnel create manim-api

# 3. Anotar o UUID retornado (ex: a1b2c3d4-5678-90ab-cdef-1234567890ab)

# 4. Criar rota DNS (substitua pelo seu dom√≠nio)
cloudflared tunnel route dns manim-api api.seudominio.com
```

### 6.3 Arquivo de configura√ß√£o

Criar `~/.cloudflared/config.yml`:

```yaml
# ~/.cloudflared/config.yml
tunnel: a1b2c3d4-5678-90ab-cdef-1234567890ab  # Seu UUID
credentials-file: /home/SEU_USER/.cloudflared/a1b2c3d4-5678-90ab-cdef-1234567890ab.json

ingress:
  - hostname: api.seudominio.com
    service: http://localhost:8000
  
  # Catch-all obrigat√≥rio (sempre no final)
  - service: http_status:404
```

### 6.4 Executar como servi√ßo systemd

```bash
# Mover configura√ß√µes para /etc/cloudflared
sudo mkdir -p /etc/cloudflared
sudo cp ~/.cloudflared/config.yml /etc/cloudflared/
sudo cp ~/.cloudflared/*.json /etc/cloudflared/

# Atualizar caminho no config.yml
sudo sed -i "s|/home/$USER/.cloudflared|/etc/cloudflared|g" /etc/cloudflared/config.yml

# Instalar servi√ßo
sudo cloudflared service install

# Iniciar e habilitar
sudo systemctl start cloudflared
sudo systemctl enable cloudflared

# Verificar status
sudo systemctl status cloudflared
```

### 6.5 Comandos √∫teis

```bash
# Ver logs em tempo real
sudo journalctl -u cloudflared -f

# Reiniciar ap√≥s mudan√ßas
sudo systemctl restart cloudflared

# Verificar tunnels ativos
cloudflared tunnel list

# Testar manualmente (debug)
cloudflared tunnel --loglevel debug run manim-api
```

---

## 7. Roadmap de implementa√ß√£o

| Fase | Tarefa | Tempo | Depend√™ncias | Prioridade |
|------|--------|-------|--------------|------------|
| **1** | Instalar depend√™ncias sistema (FFmpeg, Cairo, LaTeX) | 15-30 min | Sistema base | üî¥ Cr√≠tico |
| **2** | Criar ambiente Python e instalar requirements | 10 min | Fase 1 | üî¥ Cr√≠tico |
| **3** | Configurar .env com OpenAI API key | 5 min | Conta OpenAI | üî¥ Cr√≠tico |
| **4** | Implementar config.py e schemas.py | 10 min | Fase 2 | üî¥ Cr√≠tico |
| **5** | Implementar prompts.py com system prompt | 15 min | - | üî¥ Cr√≠tico |
| **6** | Implementar openai_service.py | 20 min | Fase 5 | üî¥ Cr√≠tico |
| **7** | Implementar manim_executor.py | 25 min | Fase 1 | üî¥ Cr√≠tico |
| **8** | Implementar main.py (FastAPI server) | 20 min | Fases 4-7 | üî¥ Cr√≠tico |
| **9** | Testar localmente com curl | 20 min | Fase 8 | üî¥ Cr√≠tico |
| **10** | Instalar cloudflared | 10 min | - | üü° Importante |
| **11** | Configurar Cloudflare Tunnel | 20 min | Dom√≠nio no Cloudflare | üü° Importante |
| **12** | Configurar como servi√ßo systemd | 10 min | Fase 11 | üü¢ Nice-to-have |
| **13** | Teste end-to-end externo | 10 min | Fase 11 | üü° Importante |

**Total estimado: 3-5 horas** (primeira vez, sem interrup√ß√µes)

---

## 8. Teste end-to-end

### 8.1 Iniciar o servidor

```bash
cd manim-api
source venv/bin/activate

# Modo desenvolvimento (com auto-reload)
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Modo produ√ß√£o
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 2
```

### 8.2 Health check

```bash
curl http://localhost:8000/

# Resposta esperada:
{
  "status": "healthy",
  "manim_version": "Manim Community v0.19.0",
  "openai_model": "gpt-5.1-codex-max"
}
```

### 8.3 Gerar apenas c√≥digo (debug)

```bash
curl -X POST http://localhost:8000/generate-code \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Create a blue circle that grows from the center and then rotates 360 degrees"
  }'

# Resposta esperada:
{
  "code": "from manim import *\n\nclass BlueCircle(Scene):\n    def construct(self):\n        circle = Circle(color=BLUE, fill_opacity=0.7)\n        self.play(GrowFromCenter(circle))\n        self.play(Rotate(circle, angle=2*PI), run_time=2)\n        self.wait()",
  "scene_name": "BlueCircle",
  "is_valid": true,
  "validation_message": "Code validated successfully"
}
```
> Sem informar `width`/`height`, assume 1920x1080 @ 60 fps.

### 8.4 Gerar v√≠deo completo (base64)

```bash
curl -X POST http://localhost:8000/generate-video \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Show the Pythagorean theorem equation a¬≤ + b¬≤ = c¬≤ with a writing animation",
    "width": 1280,
    "height": 720
  }' | jq .

# Resposta esperada (truncada):
{
  "success": true,
  "video_base64": "AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1w...",
  "content_type": "video/mp4",
  "scene_name": "PythagoreanTheorem",
  "error": null
}
```

### 8.5 Baixar v√≠deo como arquivo

```bash
# Salvar v√≠deo diretamente
curl -X POST http://localhost:8000/generate-video-file \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Transform a red square into a blue circle with smooth animation",
    "width": 1080,
    "height": 1080
  }' --output video.mp4

# Verificar arquivo
file video.mp4
# Esperado: video.mp4: ISO Media, MP4 v2 [ISO 14496-14]
```

### 8.6 Testar via Cloudflare Tunnel (externo)

```bash
# Ap√≥s configurar tunnel
curl -X POST https://api.seudominio.com/generate-video \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Draw a simple sine wave graph with animated curve",
    "width": 1080,
    "height": 1920
  }'
```

---

## 9. Problemas conhecidos e solu√ß√µes

### Erros comuns de instala√ß√£o

| Erro | Causa | Solu√ß√£o |
|------|-------|---------|
| `ModuleNotFoundError: pycairo` | Cairo n√£o instalado | `sudo apt install libcairo2-dev` e reinstalar manim |
| `LaTeX not found` | TexLive ausente | `sudo apt install texlive-latex-base` |
| `ffmpeg not found` | FFmpeg n√£o no PATH | `sudo apt install ffmpeg` |
| `ManimPango build failed` | Headers faltando | `sudo apt install libpango1.0-dev` |

### Erros em runtime

| Erro | Causa | Solu√ß√£o |
|------|-------|---------|
| `Scene 'X' not found` | Nome da cena incorreto | Verificar regex de extra√ß√£o no `get_scene_name()` |
| `TimeoutExpired` | Renderiza√ß√£o muito lenta | Usar `-ql` ou aumentar `render_timeout` |
| `Video not found after render` | Caminho diferente | Verificar estrutura de pastas, usar busca recursiva |
| `OpenAI RateLimitError` | Muitas requests | Implementar retry com backoff ou usar tier pago |

### Edge cases de gera√ß√£o de c√≥digo

| Problema | Exemplo | Mitiga√ß√£o |
|----------|---------|-----------|
| C√≥digo sem Scene class | LLM gera apenas fun√ß√µes | Few-shot com templates corretos |
| Import de m√≥dulos externos | `import numpy as np` errado | Whitelist de imports permitidos |
| Anima√ß√µes muito longas | >60 segundos | Prompt com limite expl√≠cito |
| MathTex sem LaTeX | Servidor sem texlive | Instruir LLM a usar `Text()` como fallback |

### Limita√ß√µes do MVP

- **Single-threaded**: Apenas uma renderiza√ß√£o por vez
- **Sem cache**: Mesma descri√ß√£o gera c√≥digo diferente
- **Sem retry**: Falha de OpenAI n√£o √© retentada
- **Arquivos tempor√°rios**: Limpeza autom√°tica pode falhar em crash
- **Sem autentica√ß√£o**: API aberta (mitigar com Cloudflare Access)

---

## 10. Pr√≥ximos passos p√≥s-MVP

### Melhorias de curto prazo (Prioridade Alta)

1. **Adicionar API Key authentication**
   ```python
   from fastapi.security import APIKeyHeader
   api_key = APIKeyHeader(name="X-API-Key")
   ```

2. **Implementar cache de c√≥digo gerado**
   - Hash da descri√ß√£o como key
   - Evita chamadas repetidas √† OpenAI

3. **Adicionar rate limiting**
   ```bash
   pip install slowapi
   ```

4. **Logs estruturados**
   - Usar `structlog` para JSON logging
   - M√©tricas de tempo de gera√ß√£o/renderiza√ß√£o

### Melhorias de m√©dio prazo

5. **Fila de renderiza√ß√£o com Celery/Redis**
   - Para m√∫ltiplas requests simult√¢neas
   - Status tracking de jobs

6. **Retry autom√°tico da OpenAI**
   - Backoff exponencial
   - Fallback para modelo alternativo

7. **Preview do c√≥digo antes de renderizar**
   - Endpoint separado `/preview`
   - Permite usu√°rio validar antes de gastar tempo de render

8. **Suporte a templates customizados**
   - Usu√°rio pode fornecer template base
   - Few-shot examples personalizados

### Melhorias de longo prazo

9. **Docker Compose para deploy**
   - Container Manim isolado
   - Scaling horizontal

10. **UI Web simples**
    - React/Vue frontend
    - Preview em tempo real

11. **Hist√≥rico de gera√ß√µes**
    - SQLite para persist√™ncia
    - Re-renderiza√ß√£o de c√≥digo salvo

12. **M√∫ltiplas qualidades por request**
    - Gerar 480p, 720p, 1080p em paralelo

---

## Refer√™ncia r√°pida de comandos
1. Criar/ativar ambiente:
   ```bash
   cd manim-api
   python3 -m venv venv
   source venv/bin/activate
   ```
2. Instalar depend√™ncias e preparar `.env`:
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   cp .env.example .env  # edite OPENAI_API_KEY e demais vari√°veis
   ```
3. Rodar a API no terminal:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000 --reload
   ```
4. Atualizar depend√™ncias quando necess√°rio:
   ```bash
   pip install -r requirements.txt --upgrade
   ```

---

Este relat√≥rio fornece uma implementa√ß√£o completa e funcional para o MVP do Backend API de Gera√ß√£o de V√≠deos Manim via LLM. O sistema est√° pronto para ser copiado, configurado e executado, com um tempo estimado de **4-8 horas** at√© ter o primeiro v√≠deo gerado via API.
